//Exercício desenvolvido por mim

/*1.0.1 Multi-Layer Perceptrons
The simple logistic regression example we went over in the previous notebook is essentially a onelayer neural network, projecting straight from the input to the output predictions. While this can
be effective for linearly separable data, occasionally a little more complexity is necessary. Neural
networks with additional layers are typically able to learn more complex functions, leading to better
performance. These additional layers (called “hidden” layers) transform the input into one or more
intermediate representations before making a final prediction.
In the logistic regression example, the way we performed the transformation was with a fullyconnected layer, which consisted of a linear transform (matrix multiply plus a bias). A neural
network consisting of multiple successive fully-connected layers is commonly called a Multi-Layer
Perceptron (MLP). In the simple MLP below, a 4-d input is projected to a 5-d hidden representation,
which is then projected to a single output that is used to make the final prediction.
For the assignment, you will be building a MLP for MNIST. Mechanically, this is done very similary
to our logistic regression example, but instead of going straight to a 10-d vector representing our
output predictions, we might first transform to a 500-d vector with a “hidden” layer, then to the
output of dimension 10. Before you do so, however, there’s one more important thing to consider.*/

/*1.0.2 Nonlinearities
We typically include nonlinearities between layers of a neural network. There’s a number of reasons
to do so. For one, without anything nonlinear between them, successive linear transforms (fully
connected layers) collapse into a single linear transform, which means the model isn’t any more
expressive than a single layer. On the other hand, intermediate nonlinearities prevent this collapse,
allowing neural networks to approximate more complex functions.
There are a number of nonlinearities commonly used in neural networks, but one of the most
popular is the rectified linear unit (ReLU):
x = max(0, x)
There are a number of ways to implement this in PyTorch. We could do it with elementary PyTorch
operations:*/

import torch

x = torch.rand(5, 3)*2 - 1
x_relu_max = torch.max(torch.zeros_like(x),x)

print("x: {}".format(x))
print("x after ReLU with max: {}".format(x_relu_max))

//Of course, PyTorch also has the ReLU implemented, for example in torch.nn.functional:

import torch.nn.functional as F

x_relu_F = F.relu(x)

print("x after ReLU with nn.functional: {}".format(x_relu_F))

//Same result.

/*1.0.3 Assignment
Build a 2-layer MLP for MNIST digit classfication. Feel free to play around with the model
architecture and see how the training time/performance changes, but to begin, try the following:
Image (784 dimensions) ->
fully connected layer (500 hidden units) -> nonlinearity (ReLU) ->
fully connected (10 hidden units) -> softmax
Try building the model both with basic PyTorch operations, and then again with more objectoriented higher-level APIs. You should get similar results!
Some hints: - Even as we add additional layers, we still only require a single optimizer to learn the
parameters. Just make sure to pass all parameters to it! - As you’ll calculate in the Short Answer,
this MLP model has many more parameters than the logisitic regression example, which makes it
more challenging to learn. To get the best performance, you may want to play with the learning rate
and increase the number of training epochs. - Be careful using torch.nn.CrossEntropyLoss().
If you look at the PyTorch documentation: you’ll see that torch.nn.CrossEntropyLoss() combines the softmax operation with the cross-entropy. This means you need to pass in the logits
(predictions pre-softmax) to this loss. Computing the softmax separately and feeding the result
into torch.nn.CrossEntropyLoss() will significantly degrade your model’s performance!*/

### YOUR CODE HERE

%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import torch
from tqdm.notebook import tqdm

from torchvision import datasets, transforms

mnist_train = datasets.MNIST(root="./datasets", train=True, transform=transforms.ToTensor(), download=True)
mnist_test = datasets.MNIST(root= "./datasets", train=False, transform=transforms.ToTensor(), download=True)

print("Number of MNIST training examples: {}".format(len(mnist_train)))
print("Number of MNIST test examples: {}".format(len(mnist_test)))

image, label = mnist_train[3]

print("Default image shape: {}".format(image.shape))
image = image.reshape([28,28])
print("Reshaped image shape: {}".format(image.shape))

plt.imshow(image, cmap="gray")

print("The Label for this image: {}".format(label))

train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)
test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)

data_train_iter = iter(train_loader)
images, labels = data_train_iter.next()

print("Shape of the minibatch of images: {}".format(images.shape))
print("Shape of the minibatch of labels: {}".format(labels.shape))

x = images.view(-1, 28*28)
print("The shape of input x: {}".format(x.shape))

#L1
W1 = torch.randn(784, 500)/np.sqrt(784)
W1.requires_grad_()
b1 = torch.zeros(500, requires_grad=True)

#L2
W2 = torch.randn(500, 10)/np.sqrt(784)
W2.requires_grad_()
b2 = torch.zeros(10, requires_grad=True)

y1 = torch.matmul(x, W1) + b1

print(y1[0:])

import torch.nn.functional as F
L2 = F.relu(y1)
y2 = torch.matmul(L2, W2) + b2
print(y2[0,:])

py = F.softmax(y2, dim=1)
print("py[0] with torch.nn.functional.softmax: {}".format(py[0]))

print(labels.shape)

cross_entropy = F.cross_entropy(y2, labels)
print("cross entropy with torch.nn.functional.cross_entropy: {}".format(cross_entropy))

optimizer = torch.optim.SGD([W1, b1, W2, b2], lr=0.1)

b2.grad

optimizer.step()

b2

print("b.grad before zero_grad(): {}".format(b2.grad))
optimizer.zero_grad()
print("b.grad after zero_grad(): {}".format(b2.grad))

epochs = 10

for ep in range (epochs):
    for images, labels in tqdm(train_loader):
        optimizer.zero_grad()
    
        x = images.view(-1, 28*28)
        y3 = torch.matmul(x, W1) + b1
        L3 = F.relu(y3)
        y4 = torch.matmul(L3, W2) + b2
        cross_entropy = F.cross_entropy(y4, labels)
        
        cross_entropy.backward()
        optimizer.step()

correct = 0
total = len(mnist_test)

with torch.no_grad():
    for images, labels in tqdm (test_loader):
        x = images.view(-1, 28*28)
        y3 = torch.matmul(x, W1)+b1
        L3 = F.relu(y3)
        y4 = torch.matmul(L3, W2) + b2
        
        predictions = torch.argmax(y4, dim=1)
        correct += torch.sum((predictions == labels).float())
        
print("Test accuracy: {}".format(correct/total))

/*1.0.4 Short answer
How many trainable parameters does your model have? How does this compare to the logisitic
regression example?
10 trainable parameters. Test accuracy: 0.9781000018119812*/
